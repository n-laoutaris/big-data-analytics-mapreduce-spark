{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21ce31ce",
   "metadata": {},
   "source": [
    "# Mini-project: MapReduce - Car prices\n",
    "\n",
    "This notebook demonstrates MapReduce analytics on a car sales dataset using Python and MRJob. It was created as part of my Big Data class and serves as my first hands-on project using MapReduce."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c94172",
   "metadata": {},
   "source": [
    "## Input file description\n",
    "\n",
    "We are using the `car_prices.csv` input file. It is a Comma Separated Values (CSV) file that provides information pertaining to the sales transactions of various vehicles. The dataset comprises 558837 rows and 16 columns and occupies around 85 MB.\n",
    "\n",
    "Each row denotes a car sale. The columns represent:\n",
    "\n",
    "1. `year`: The manufacturing year of the vehicle.\n",
    "2. `make`: The brand or manufacturer of the vehicle.\n",
    "3. `model`: The specific model of the vehicle.\n",
    "4. `trim`: Additional designation for the vehicle model.\n",
    "5. `body`: The body type of the vehicle (e.g., SUV, Sedan).\n",
    "6. `transmission`: The type of transmission in the vehicle (e.g., automatic).\n",
    "7. `vin`: Vehicle Identification Number, a unique code for each vehicle.\n",
    "8. `state`: The state where the vehicle is registered.\n",
    "9. `condition`: Condition of the vehicle, possibly rated on a scale.\n",
    "10. `odometer`: The mileage or distance traveled by the vehicle.\n",
    "11. `color`: Exterior color of the vehicle.\n",
    "12. `interior`: Interior color of the vehicle.\n",
    "13. `seller`: The entity selling the vehicle.\n",
    "14. `mmr`: Manheim Market Report, possibly indicating the estimated market value of the vehicle.\n",
    "15. `sellingprice`: The price at which the vehicle was sold.\n",
    "16. `saledate`: The date and time when the vehicle was sold.\n",
    "\n",
    "Dataset source: [https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data](https://www.kaggle.com/datasets/syedanwarafridi/vehicle-sales-data)\n",
    "\n",
    "Similarly to almost all real-world datasets, this one has several data quality issues. One of these issues has to do with missing values. Therefore, there might be missing dates, brands, prices, colors, etc. Imputing missing values is out of the scope of this project. Consequently, in **all**  implementations,  **we simply ignore all the rows that have missing values on columns 1, 2, 10, 11, 12, 15, and 16.** Fortunately, only a small portion of the records is going to be lost with this strategy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39315bfa",
   "metadata": {},
   "source": [
    "## 1: Compute Yearly Statistics\n",
    "\n",
    "In this job we are interested in computing yearly statistics about car sales. In particular, we implement a MapReduce task that computes the:\n",
    "\n",
    "* number of vehicles per year,\n",
    "* total value of the sold cars per year,\n",
    "* average distance travelled by the sold cars per year and\n",
    "* average age of the sold cars per year.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216a8919",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file task1.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class Task1(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        columns = line.split(\",\")\n",
    "        \n",
    "        # Skip rows with missing values for these columns\n",
    "        for i in [0, 1, 9, 10, 11, 14, 15]:\n",
    "            if not columns[i].strip():\n",
    "                return\n",
    "\n",
    "        saledate = columns[15]\n",
    "        try:    \n",
    "            year = int(saledate.split()[3])\n",
    "        except IndexError:  # Probably an invalid date\n",
    "            return\n",
    "            \n",
    "        price = float(columns[14])\n",
    "        distance = float(columns[9])\n",
    "        manufactured_on = int(columns[0])\n",
    "        age = year - manufactured_on\n",
    "        yield year, (1, price, distance, age)\n",
    "\n",
    "    def reducer(self, year, values):\n",
    "        total_count = 0\n",
    "        total_price = 0\n",
    "        total_distance = 0\n",
    "        total_age = 0\n",
    "\n",
    "        for count, price, distance, age in values:\n",
    "            total_count += count\n",
    "            total_price += price\n",
    "            total_distance += distance\n",
    "            total_age += age\n",
    "\n",
    "        yield year, (total_count, total_price, total_distance/total_count, total_age/total_count)\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    Task1.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6e37e0",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18c5df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the job here in both standalone and distributed modes.\n",
    "\n",
    "!python3 task1.py car_prices.csv \n",
    "\n",
    "!python3 task1.py -r hadoop car_prices.csv -o task1_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ac1522",
   "metadata": {},
   "source": [
    "## 2: Compute Yearly Statistics per Brand\n",
    "\n",
    "In this job we are interested in the performance of the car sales **per brand, in a yearly fashion**. In fact, this will compute the same statistics as those of the job above, but also groupped by brand. More specifically, we are interested in computing the:\n",
    "\n",
    "* number of vehicles per year, per brand,\n",
    "* total value of the sold cars per year, per brand,\n",
    "* average distance travelled by the sold cars per year, per brand and\n",
    "* average age of the sold cars per year per brand.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fd8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file task2.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class Task2(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        columns = line.split(\",\")\n",
    "        \n",
    "        # Skip rows with missing values for these columns\n",
    "        for i in [0, 1, 9, 10, 11, 14, 15]:\n",
    "            if not columns[i].strip():\n",
    "                return  \n",
    "\n",
    "        saledate = columns[15]\n",
    "        try:    \n",
    "            year = int(saledate.split()[3])\n",
    "        except IndexError:  # Probably an invalid date\n",
    "            return\n",
    "            \n",
    "        price = float(columns[14])\n",
    "        distance = float(columns[9])\n",
    "        manufactured_on = int(columns[0])\n",
    "        age = year - manufactured_on\n",
    "        brand = columns[1]\n",
    "        yield (year, brand), (1, price, distance, age)\n",
    "\n",
    "    def reducer(self, keys, values):\n",
    "        total_count = 0\n",
    "        total_price = 0\n",
    "        total_distance = 0\n",
    "        total_age = 0\n",
    "\n",
    "        for count, price, distance, age in values:\n",
    "            total_count += count\n",
    "            total_price += price\n",
    "            total_distance += distance\n",
    "            total_age += age\n",
    "\n",
    "        year, brand = keys\n",
    "\n",
    "        yield (year, brand), (total_count, total_price, total_distance / total_count, total_age / total_count)\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    Task2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0920f7",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d60e5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the job here in both standalone and distributed modes.\n",
    "\n",
    "!python3 task2.py car_prices.csv \n",
    "\n",
    "!python3 task2.py -r hadoop car_prices.csv -o task2_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b108a05",
   "metadata": {},
   "source": [
    "## 3: Large-scale analytics: Feature Exploration\n",
    "\n",
    "In this job we will perform a part of what is called feature exploration. Feature exploration focuses on quantifying the impact of a particular feature on the target variable. While such analyses typically include all features, in this example we are only interested in finding out how the (exterior) color of a car affects its sales. More specifically, we need to compute:\n",
    "\n",
    "* number of vehicles per (exterior) color, and\n",
    "* the total value of the sold cars per color.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67c33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file task3.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class Task3(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        columns = line.split(\",\")\n",
    "        \n",
    "        # Skip rows with missing values for these columns\n",
    "        for i in [0, 1, 9, 10, 11, 14, 15]:\n",
    "            if not columns[i]:\n",
    "                return  \n",
    "            \n",
    "        price = float(columns[14])\n",
    "        color = columns[10]\n",
    "        if str.isdigit(color) or color == \"\\u2014\":  # Trial and error showed numbers and dashes in some rows. Interpreting them as missing and skipping those rows.\n",
    "            return\n",
    "        yield color, (1, price)\n",
    "\n",
    "    def reducer(self, color, values):\n",
    "        total_count = 0\n",
    "        total_price = 0\n",
    "\n",
    "        for count, price in values:\n",
    "            total_count += count\n",
    "            total_price += price\n",
    "\n",
    "        yield color, (total_count, total_price)\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    Task3.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d21684e",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16939d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the job here in both standalone and distributed modes.\n",
    "\n",
    "!python3 task3.py car_prices.csv \n",
    "\n",
    "!python3 task3.py -r hadoop car_prices.csv -o task3_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5604609c",
   "metadata": {},
   "source": [
    "## 4: Exploratory Analysis\n",
    "\n",
    "In this job we will perform a part of what is called exploratory analysis. This process applies unsupervised techniques to a data collection with the aim of discovering potentially useful information. In this example we are interested in finding out the combination of exterior and interior colors that sells most. More specifically, we need to compute:\n",
    "\n",
    "* the number of vehicles per pair of exterior/interior color.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071897ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file task4.py\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "from mrjob.job import MRJob\n",
    "\n",
    "class Task4(MRJob):\n",
    "\n",
    "    def mapper(self, _, line):\n",
    "        columns = line.split(\",\")\n",
    "        \n",
    "        # Skip rows with missing values for these columns\n",
    "        for i in [0, 1, 9, 10, 11, 14, 15]:\n",
    "            if not columns[i]:\n",
    "                return \n",
    "            \n",
    "        color_ex = columns[10]\n",
    "        color_in = columns[11]\n",
    "\n",
    "        if str.isdigit(color_ex) or color_in == \"\\u2014\" or color_ex == \"\\u2014\":  # Same as previous task\n",
    "            return\n",
    "        yield (color_ex, color_in), 1\n",
    "\n",
    "    def reducer(self, colors, counts):             \n",
    "        color_ex, color_in = colors\n",
    "        \n",
    "        yield (color_ex, color_in), sum(counts)\n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    Task4.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3636d2c",
   "metadata": {},
   "source": [
    "### Running the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7de1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We run the job here in both standalone and distributed modes.\n",
    "\n",
    "!python3 task4.py car_prices.csv \n",
    "\n",
    "!python3 task4.py -r hadoop car_prices.csv -o task4_out\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
